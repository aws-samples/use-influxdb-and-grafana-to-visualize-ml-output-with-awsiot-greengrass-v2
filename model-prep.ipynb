{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54fbf74f",
   "metadata": {},
   "source": [
    "## Model Preparation for Grafana/InfluxDB demo\n",
    "In this notebook, we are going to take a basic Resnet-18 PyTorch model, and pre-process it to be compiled with Amazon SageMaker NEO. As a first step, we import the following libraries. \n",
    "\n",
    "Please note, that this notebook should be run with kernel `conda_pytorch_latest_p36`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac43ab4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tarfile\n",
    "import boto3\n",
    "import sagemaker\n",
    "import time\n",
    "from sagemaker.utils import name_from_base\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75415235",
   "metadata": {},
   "source": [
    "[Optional] Check that your PyTorch version is at least 1.6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f392ec21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20399ad4",
   "metadata": {},
   "source": [
    "Download the sample [PyTorch Resnet-18 model](https://pytorch.org/hub/pytorch_vision_resnet/) trained with 1000 classes with [ImageNet](https://image-net.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb4fcc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ec2-user/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2f3f1c",
   "metadata": {},
   "source": [
    "Download some sample images for us to later test model validity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93508c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
    "try: urllib.URLopener().retrieve(url, filename)\n",
    "except: urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2254b43",
   "metadata": {},
   "source": [
    "For frameworks that come with different frameworks, the preparation step for the model can be slightly different. Please refer to [this guide for more information on the pre-processing steps](https://docs.aws.amazon.com/sagemaker/latest/dg/neo-compilation-preparing-model.html) for MXNet, TensorFlow, PyTorch, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25d50e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Resnet classification models take input pictures in the following size\n",
    "input_shape = [1, 3, 224, 224]\n",
    "trace = torch.jit.trace(model.float().eval(), torch.zeros(input_shape).float())\n",
    "trace.save(\"model.pth\")\n",
    "with tarfile.open(\"model.tar.gz\", \"w:gz\") as f:\n",
    "    f.add(\"model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf549ed",
   "metadata": {},
   "source": [
    "In this step, we prepare for compilation jobs. SageMaker has a default bucket for each account (starts with sagemaker-) in the same region of this notebook instance. We are going to store all of the artifacts and compiled models within that default bucket. Feel free to change the bucket location if needed otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0302bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::593512547852:role/service-role/AmazonSageMaker-ExecutionRole-20200723T133094\n"
     ]
    }
   ],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "print(role)\n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_region_name\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "compilation_job_name = name_from_base(\"TorchVision-ResNet18-Neo\")\n",
    "prefix = compilation_job_name + \"/model\"\n",
    "model_path = sess.upload_data(path=\"model.tar.gz\", key_prefix=prefix)\n",
    "\n",
    "data_shape = '{\"input0\":[1,3,224,224]}'\n",
    "target_platform = {'Os': 'LINUX','Arch': 'X86_64'}\n",
    "framework = \"PYTORCH\"\n",
    "framework_version = \"1.6\"\n",
    "compiled_model_path = \"s3://{}/{}/output\".format(bucket, compilation_job_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ddf9ed",
   "metadata": {},
   "source": [
    "Start compilation job, and start a polling process to wait for the compilation job to succeed. It could take around 5 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7574e557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling ...\n",
      "Compiling ...\n",
      "Compiling ...\n",
      "Compiling ...\n",
      "Compiling ...\n",
      "Compiling ...\n",
      "Compiling ...\n",
      "Compiling ...\n",
      "Compiling ...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Create a SageMaker client so you can submit a compilation job\n",
    "sagemaker_client = boto3.client('sagemaker', region_name='us-west-2')\n",
    "\n",
    "response = sagemaker_client.create_compilation_job(\n",
    "    CompilationJobName=compilation_job_name,\n",
    "    RoleArn=role,\n",
    "    InputConfig={\n",
    "        'S3Uri': model_path,\n",
    "        'DataInputConfig': data_shape,\n",
    "        'Framework': framework.upper()\n",
    "    },\n",
    "    OutputConfig={\n",
    "        'S3OutputLocation': compiled_model_path,\n",
    "        'TargetPlatform': target_platform \n",
    "    },\n",
    "    StoppingCondition={\n",
    "        'MaxRuntimeInSeconds': 900\n",
    "    }\n",
    ")\n",
    "while True:\n",
    "    response = sagemaker_client.describe_compilation_job(CompilationJobName=compilation_job_name)\n",
    "    if response['CompilationJobStatus'] == 'COMPLETED':\n",
    "        break\n",
    "    elif response['CompilationJobStatus'] == 'FAILED':\n",
    "        raise RuntimeError('Compilation failed')\n",
    "    print('Compiling ...')\n",
    "    time.sleep(30)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f4c918",
   "metadata": {},
   "source": [
    "Since NEO compilation output is in the format of `.tar.gz`, but AWS IoT Greengrass only accepts `.zip`. We need the following step to convert the compiled model to convert the format in order for the archived file to be downloaded and unpacked by Greengrass service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1800e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiled.params\n",
      "compiled.meta\n",
      "compiled_model.json\n",
      "compiled.so\n",
      "libdlr.so\n",
      "dlr.h\n",
      "manifest\n",
      "  adding: model/compiled.meta (deflated 66%)\n",
      "  adding: model/compiled_model.json (deflated 93%)\n",
      "  adding: model/compiled.params (deflated 7%)\n",
      "  adding: model/compiled.so (deflated 77%)\n",
      "  adding: model/dlr.h (deflated 83%)\n",
      "  adding: model/libdlr.so (deflated 60%)\n",
      "  adding: model/manifest (deflated 45%)\n"
     ]
    }
   ],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "object_path = '{}/output/model-{}_{}.tar.gz'.format(compilation_job_name, target_platform['Os'], target_platform['Arch'])\n",
    "neo_compiled_model = 'compiled-model.tar.gz'\n",
    "s3_client.download_file(bucket, object_path, neo_compiled_model)\n",
    "!mkdir model\n",
    "!tar zfxv compiled-model.tar.gz -C model/\n",
    "!zip compiled-model.zip model/*\n",
    "s3_client.upload_file('compiled-model.zip', bucket, '{}/output/model-{}_{}.zip'.format(compilation_job_name, target_platform['Os'], target_platform['Arch']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4804414",
   "metadata": {},
   "source": [
    "This is the end of this brief notebook on how to prepare a Amazon SageMaker NEO compiled model. Please refer to [developer's guide](https://docs.aws.amazon.com/sagemaker/latest/dg/neo.html) for more information on Amazon SageMaker NEO service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80ad113",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
